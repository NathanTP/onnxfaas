"""emotion_ferplus model and code based on https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/onnx/onnx-inference-facial-expression-recognition-deploy.ipynb"""

import pathlib
# import json
# import time
# import onnxruntime
# import numpy as np
# import onnx
# import onnx.numpy_helper
import cProfile

# This is done weird for profiling purposes so I can measure the time
# contribution of imports
def imports():
    for m in ['json', 'time', 'onnxruntime', 'onnx']:
        globals()[m] = __import__(m)

    globals()['np'] = __import__("numpy")
    import onnx.numpy_helper

ferPath = pathlib.Path("../data/emotion_ferplus")
ferModelPath = ferPath / "model.onnx"


def initFer():
    opts = onnxruntime.SessionOptions()
    # opts.optimized_model_filepath = "optModel.onnx"
    opts.enable_profiling = True

    # ferModelPath="./optModel.onnx"
    ferSession = onnxruntime.InferenceSession(
            str(ferModelPath),
            sess_options=opts,
            providers=["CPUExecutionProvider"])

    # ferSession.set_providers(['CUDAExecutionProvider'])
    # ferSession.set_providers(['CPUExecutionProvider'])
    return {
            "session" : ferSession,
            "inputName" : ferSession.get_inputs()[0].name,
            "outputName" : ferSession.get_outputs()[0].name,
        }


def emotion_map(classes, N=1):
    """Take the most probable labels (output of postprocess) and returns the 
    top N emotional labels that fit the picture."""

    emotion_table = {'neutral':0, 'happiness':1, 'surprise':2, 'sadness':3, 
                     'anger':4, 'disgust':5, 'fear':6, 'contempt':7}

    emotion_keys = list(emotion_table.keys())
    emotions = []
    for i in range(N):
        emotions.append(emotion_keys[classes[i]])
    return emotions


def softmax(x):
    """Compute softmax values (probabilities from 0 to 1) for each possible label."""
    x = x.reshape(-1)
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum(axis=0)


def toClassIds(scores):
    """This function takes the scores generated by the network and 
    returns the class IDs in decreasing order of probability."""
    prob = softmax(scores)
    prob = np.squeeze(prob)
    classes = np.argsort(prob)[::-1]
    return classes


def preProcess(datString):
    """Load fer input from a protobuf string"""
    tensor = onnx.TensorProto()
    tensor.ParseFromString(datString)

    npDat = onnx.numpy_helper.to_array(tensor)
    jsonDat = json.dumps({'data': npDat.tolist()})
    return jsonDat


def postProcess(onnxRes):
    """Take the result from session.run() and turn it into a json response"""
    result = emotion_map(toClassIds(onnxRes[0]))
    result_dict = {"result": result}
    return json.dumps(result_dict)


def run(state, event):
    # load in our data, convert to readable format
    data = np.array(json.loads(event)['data']).astype('float32')

    r = state['session'].run([state['outputName']], {state['inputName'] : data})

    return postProcess(r)

def testFer(state):
    test_inputs = []
    test_outputs = []

    # Load a test image (we'll just use the same image over and over for simplicity)
    with open(ferPath / 'test_data_set_0' / 'input_0.pb', 'rb') as f:
        inStr = f.read()

    # for repeat in range(10000):
    for repeat in range(1):
        testInput = preProcess(inStr)

        # predict using the deployed model
        r = json.loads(run(state, testInput))

        if "error" in r:
            print(r['error'])
            break

        result = r['result'][0]

def main():
    # cProfile.runctx("imports()", globals=globals(), locals=locals(), sort="cumulative", filename="ferImports.prof")
    imports()
    ferState = initFer()
    testFer(ferState)

    prof_file = ferState['session'].end_profiling()
    print(prof_file)

if __name__ == "__main__":
    main()
    # cProfile.run("main()", sort="cumulative", filename="fer10kGPU.prof")
